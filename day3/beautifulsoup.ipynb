{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¥£ Mastering Web Scraping with BeautifulSoup\n",
    "---\n",
    "## 1. Introduction\n",
    "**BeautifulSoup** is a Python library for parsing HTML and XML documents. It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping.\n",
    "\n",
    "### Why BeautifulSoup?\n",
    "* **Robustness**: It handles poorly formatted HTML (missing tags, bad nesting) without crashing.\n",
    "* **Simplicity**: It provides Pythonic ways to search and navigate the DOM tree.\n",
    "* **Compatibility**: It works with different parsers like `lxml` and `html5lib`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Installation\n",
    "You need `beautifulsoup4` for parsing and `requests` to fetch the webpage content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4 requests lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Understanding the HTML Tree Structure\n",
    "Every HTML page is a hierarchical tree of tags. \n",
    "\n",
    "\n",
    "\n",
    "To extract data, you need to navigate this tree. Let's start with a sample string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_content = \"\"\"\n",
    "<html>\n",
    "    <head><title>The Python Store</title></head>\n",
    "    <body>\n",
    "        <h1 id=\"main-title\">Welcome to the Store</h1>\n",
    "        <p class=\"description\">We sell high-quality Python scripts.</p>\n",
    "        <ul class=\"item-list\">\n",
    "            <li class=\"product\" price=\"$10\">Web Scraper Tool</li>\n",
    "            <li class=\"product\" price=\"$20\">Data Cleaner</li>\n",
    "            <li class=\"product\" price=\"$50\">Auto-Blogger</li>\n",
    "        </ul>\n",
    "        <a href=\"https://example.com/contact\" id=\"contact-link\">Contact Us</a>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Create the 'soup' object\n",
    "soup = BeautifulSoup(html_content, 'lxml')\n",
    "\n",
    "print(\"Soup Object Created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Searching the Tree\n",
    "### A. `find()` vs `find_all()`\n",
    "* `find()`: Returns the first matching element.\n",
    "* `find_all()`: Returns a list of all matching elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the main heading\n",
    "title = soup.find('h1')\n",
    "print(f\"Title Tag: {title.text}\")\n",
    "\n",
    "# Find all product items\n",
    "products = soup.find_all('li', class_='product')\n",
    "for item in products:\n",
    "    print(f\"Product Name: {item.text} | Price: {item['price']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Selecting by ID and Attributes\n",
    "You can target elements precisely using their unique IDs or specific attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding by ID\n",
    "contact = soup.find(id=\"contact-link\")\n",
    "print(f\"Link URL: {contact['href']}\")\n",
    "\n",
    "# Using CSS Selectors (similar to Javascript/CSS)\n",
    "desc = soup.select_one(\".description\")\n",
    "print(f\"Description: {desc.get_text()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Real-World Project: Scraping a Live Website\n",
    "We will scrape quotes from `quotes.toscrape.com` and store them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "URL = \"http://quotes.toscrape.com/\"\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "# Locate all quote containers\n",
    "quote_divs = soup.find_all('div', class_='quote')\n",
    "\n",
    "scraped_data = []\n",
    "\n",
    "for div in quote_divs:\n",
    "    text = div.find('span', class_='text').text\n",
    "    author = div.find('small', class_='author').text\n",
    "    tags = [tag.text for tag in div.find_all('a', class_='tag')]\n",
    "    \n",
    "    scraped_data.append({\n",
    "        'quote': text,\n",
    "        'author': author,\n",
    "        'tags': tags\n",
    "    })\n",
    "\n",
    "# Print the first result\n",
    "print(scraped_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving Data to CSV\n",
    "Finally, let's export our scraped data to a CSV file using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(scraped_data)\n",
    "df.to_csv('quotes.csv', index=False)\n",
    "print(\"Data saved to quotes.csv successfully!\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŽ¯ Summary Checklist\n",
    "1. **Inspect**: Use Browser DevTools (F12) to find the tags/classes you need.\n",
    "2. **Request**: Use `requests.get()` to fetch the HTML.\n",
    "3. **Parse**: Use `BeautifulSoup(html, 'lxml')`.\n",
    "4. **Extract**: Use `find()`, `find_all()`, or `select()`.\n",
    "5. **Clean**: Use `.text` and `.strip()` to clean the data.\n",
    "6. **Store**: Use `pandas` for easy CSV/Excel export."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}